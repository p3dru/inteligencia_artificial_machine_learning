## Capítulo 8: Tópicos complementares

### Pré-processamento:
É uma etapa crucial o pipeline* de aprendizado de máquina que envolve a limpeza e transformação dos dados brutos para que estejam em um formato adequado para serem usados. Sempre é interessante estudar quais técnicas utilizar.
> Pipeline: Um pipeline em aprendizado de máquina é uma sequência de etapas de processamento de dados que transformam os dados brutos em insights úteis. O pipeline automatiza o fluxo de trabalho de aprendizado de máquina, facilitando a execução de tarefas complexas e melhorando a eficiência e a reprodutibilidade do processo. Pré-processamento -> Seleção de atributos -> Modelagem -> Avaliação -> Implantação.
### Algumas técnicas:
 - _**Valores faltantes:**_ Podemos lidar de diversas formas, como, substituindo  valores faltantes por um específico como média, mediana ou moda dos valores existentes na coluna (imputação), remoção de linhas ou colunas que contêm valores que contém linhas faltantes (deleção), estimação dos valores com base em valores existentes, como interpolação linear* para dados sequenciais (interpolação), utilização de um modelo de aprendizado de máquina para prever os valores faltantes com base em outras características (modelo de previsão).
 - _**Normalização:**_ É uma técnica usada para transformar os valores de variáveis numéricas em uma escala comum, sem distorcer as diferenças nos intervalos de valores ou na distribuição dos dados. Se os recursos (dados) estiverem em escalas diferentes, o algoritmo pode dar mais peso a recursos com maiores valores, o que pode levar a resultados relativamente inferiores.
 - _**Discretização:**_ É o processo de transformar variáveis contínuas em variáveis categóricas. É feito dividindo o intervalo de valores possíveis da variável em um número fixo de intervalos (bins). Exemplos: MIN-MAX e Z-Score.
  > Normalização MIN-MAX: Redimensiona os valores para um intervalo específico, geralmente entre 0 e 1. (Buscar a fórmula para a normalização).<br>
  > Normalização Z-Score: Redimensiona os valores para terem uma média de 0 e um desvio padrão de 1.
 - _**Seleção de atributos:**_  Envolve a escolha de um subconjunto de atributos de um conjunto de dados para usar em um modelo de aprendizado de máquina. Pode ser feita por várias razões, incluindo a redução de dimensionalidade, melhoria na eficiência computacional e o risco de overfitting. Pode ser feita tanto manualmente quanto usando técnicas estatísticas. Alguns exemplos:
    - *Seleção de atributos univariados:* Avalia a importância de cada atributo individualmente, sem considerar as interações entre atributos. Uma abordagem comum é usar medidas de correlação, como o coeficiente de correlação de Pearson, para medir a força da relação entre cada atributo e a variável de destino.
    - *Seleção de Atributos Recursivos:* Esta técnica usa algoritmos de aprendizado de máquina para construir um modelo de aprendizado de máquina (como uma árvore de decisão ou uma floresta aleatória) e, em seguida, seleciona os atributos que contribuem mais para a construção do modelo.
    - *Seleção de atributos Multivariados:* Esta técnica considera as interações entre atributos. Uma abordagem comum é usar métodos de importância de atributos que levam em conta as interações entre atributos, como o método de importância de atributos de floresta aleatória.
    - *Seleção de Atributos Baseada em Modelos:* Esta técnica usa modelos de aprendizado de máquina para selecionar os atributos que são mais importantes para a previsão da variável de destino. Por exemplo, o método de importância de atributos de floresta aleatória pode ser usado para selecionar os atributos mais importantes.
 - _**Redução de dimensionalidade:**_ Visa reduzir o número de variáveis em um conjunto de dados, mantendo a maior quantidade possível de informação, é importante pois melhora a eficiência computacional, pois excluindo dados menos relevantes, os algoritmos precisam processar menos dados. Facilita a visualização de dados em espaços com menor dimensão com em 2D e 3D, o que pode ser útil para a análise exploratória e interpretação dos dados. Reduz o risco de overfitting, pois com menos variáveis, os algoritmos são  menos propensos a capturar ruídos nos dados, além de melhorar a interpretabilidade. Existem várias técnicas de redução de dimensionalidade, incluindo:
    - *PCA (Análise de Componentes Principais):* Transforma o conjunto de dados e um novo conjunto, de variáveis não correlacionadas (ortogonais) e que capturam a maior variância nos dados originais.
    - *T-SNE (T- Distributed Stochastic Neighbor Embedding):* Particularmente útil para a visualização de dados de alta dimensão. Preserva as distâncias locais entre os pontos de dados, o que pode ser útil para identificar clusters e estuturas de dados.
 - _**Agrupamento:**_ O agrupamento é uma técnica de aprendizado de máquina não supervisionada que agrupa dados semelhantes em grupos ou clusters. O objetivo do agrupamento é identificar estruturas ou padrões nos dados que não são facilmente acessíveis por meio de métodos de análise estatística tradicionais. Os dados agrupados podem ser usados para análise exploratória, para visualização de dados, para redução de dimensionalidade, entre outros.
 - _**Detecção de outliers:**_ Processo de identificação de pontos de dados que são significativamente diferentes dos outros pontos no conjunto de dados. Outliers podem ser causados por erros de medição, erros de entrada de dados, ou podem representar fenômenos interessantes que merecem análise profunda. É uma etapa importante para o processamento , pois pode afetar significativamente os resultados da machine learning.
 - _**Séries temporais:**_ As séries temporais são conjuntos de dados que são coletados ao longo do tempo. Elas são usadas em uma ampla gama de aplicações, incluindo previsão de vendas, análise de tendências, monitoramento de sistemas, entre outros. As séries temporais podem ser observadas (onde os valores são registrados em intervalos regulares) ou não observadas (onde os valores são estimados ou previstos). Componentes das séries temporais, tempo ( o eixo de tempo é crucial para séries temporais pois os dados são coletados ao longo do tempo
), valores (Os valores observados ou estimados na série), frequência de corte (a frequência onde os valores  são coletados (mensamente, semanalmente…).
). Alguns modelos:
    - *Modelos ARIMA (Autoregressive Integrated Moving Average):* Um modelo estatístico que combina componentes autoregressivos (utiliza os valores anteriores na série temporal para prever o próximo valor), diferenciais (diferencia a série temporal para remover a tendência e a sazonalidade, tornando os dados mais estáveis) e médias móveis (utiliza os erros dos modelos autoregressivos para prever o próximo valor) para prever séries temporais . O modelo ARIMA é uma das abordagens mais populares para modelar séries temporais.
    - *Modelos de Séries Temporais com Redes Neurais:*  Redes neurais podem ser treinadas para prever séries temporais, capturando padrões complexos e não lineares nos dados. As Redes Neurais são uma abordagem poderosa para modelar séries temporais, especialmente quando há padrões complexos e não lineares nos dados. As Redes Neurais podem capturar dependências temporais complexas e não lineares, tornando-as adequadas para uma ampla gama de problemas de séries temporais.
    - *Modelos de Séries Temporais com Máquinas de Vetores de Suporte (SVM):* SVMs podem ser usados para prever séries temporais, especialmente quando há uma estrutura temporal complexa nos dados. As Máquinas de Vetores de Suporte (SVM) são outra abordagem poderosa para modelar séries temporais. Elas são particularmente úteis quando há uma estrutura temporal complexa nos dados, como quando há múltiplas tendências ou sazonalidades. As SVMs podem ser treinadas para prever o próximo valor na série temporal com base em uma combinação de valores anteriores e suas posições temporais.
    - *Modelos de Séries Temporais com Árvores de Decisão e Florestas Aleatórias:* Árvores de decisão e florestas aleatórias também podem ser usadas para modelar séries temporais, especialmente quando os dados são não lineares ou quando há uma estrutura temporal complexa. Esses modelos podem capturar interações complexas entre os valores anteriores e suas posições temporais para prever o próximo valor.
    - *Modelos de Séries Temporais com Métodos de Ensemble:* Métodos de ensemble, como o modelo de previsão de séries temporais baseado em regressão (Prophet) da Facebook, combinam várias técnicas de modelagem para fornecer previsões robustas e precisas. O Prophet, por exemplo, utiliza modelos de tendência, sazonalidade e eventos para prever séries temporais, tornando-o adequado para uma ampla gama de problemas.
